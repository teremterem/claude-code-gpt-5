OPENAI_API_KEY=

# OPTIONAL: Set the Anthropic API key if you still want to use Anthropic models
# (which you can do by unsetting some of the remaps below in this file, or by
# explicitly setting them to map back to the Anthropic models).
#ANTHROPIC_API_KEY=

# RECOMMENDED: You are better off relying on the remaps below, rather than
# setting the desired model in Claude Caude CLI via `claude --model gpt-5-...`
# (even though you could also do that).
#
# The reason being that there are some built-in agents in Claude Code that do
# not inherit the model that was chosen globaly for the CLI and instead are
# hardwired to always use specific models by Anthropic.
#
# (If you do not want to use these remaps but also want to avoid getting
# warnings, then, instead of commenting them out, simply set them to empty
# strings.)
REMAP_CLAUDE_HAIKU_TO=gpt-5-nano-reason-minimal
REMAP_CLAUDE_SONNET_TO=gpt-5-reason-medium
REMAP_CLAUDE_OPUS_TO=gpt-5-reason-high

# OPTIONAL: Set a master key to protect the proxy
# If set, the LiteLLM proxy will require clients to provide this key on each
# request. Clients can authenticate by sending one of the following headers:
#   - Authorization: Bearer <LITELLM_MASTER_KEY>
#   - X-API-KEY: <LITELLM_MASTER_KEY>
# Useful when exposing the proxy beyond localhost or in shared environments.
# Leave unset to disable proxy-level authentication.
#LITELLM_MASTER_KEY=

# TIP: When using Claude Code CLI against this proxy, you can inline
# ANTHROPIC_API_KEY and the base URL in the same command. If you are
# currently logged in to Anthropic in the CLI, log out first so it uses
# your proxy instead of Anthropic's cloud.
# Example:
#   ANTHROPIC_API_KEY=dummy ANTHROPIC_BASE_URL=http://localhost:4000 claude

# OPTIONAL: Override base URLs if needed
#OPENAI_BASE_URL=https://api.openai.com/v1
#ANTHROPIC_BASE_URL=https://api.anthropic.com

# RECOMMENDED: Keep the setting below `true` (or unset, which is equivalent).
# Claude Code CLI cannot handle multiple tool calls in a single model response,
# which GPT-5 with medium/high reasoning effort may attempt.
#ENFORCE_ONE_TOOL_CALL_PER_RESPONSE=true

# OPTIONAL: Langfuse configuration for logging all LiteLLM requests/responses.
# Useful for debugging.
#
# NOTE: If you set these keys, make sure to install Langfuse with either
# `uv sync --all-extras` or `uv sync --extra langfuse`
#LANGFUSE_SECRET_KEY="sk-..."
#LANGFUSE_PUBLIC_KEY="pk-..."
#LANGFUSE_HOST="https://cloud.langfuse.com"
