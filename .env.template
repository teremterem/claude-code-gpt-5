# LLM provider specific environment variables. Check out the following resource
# to learn more about all the providers (and, consequently, environment
# variables) LiteLLM supports: https://docs.litellm.ai/docs/providers
OPENAI_API_KEY=
#OPENAI_BASE_URL=https://api.openai.com/v1

# OPTIONAL: Authentication for the LiteLLM server (recommended when exposing
# the server beyond your machine). Set a strong random key to require clients
# to authenticate to the LiteLLM server.
#LITELLM_MASTER_KEY=

# OPTIONAL: Langfuse configuration for logging LiteLLM request/response traces.
# Useful for debugging.
#
# NOTE: If you set these keys, make sure to install Langfuse with either
# `uv sync --all-extras` or `uv sync --extra langfuse`
#LANGFUSE_SECRET_KEY="sk-..."
#LANGFUSE_PUBLIC_KEY="pk-..."
#LANGFUSE_HOST="https://cloud.langfuse.com"

# OPTIONAL: Alternative logging of LiteLLM request/response traces (as well as
# potential conversions between ChatCompletions API and Responses API) in the
# form of local markdown files written to `.traces/` folder. Makes it easier to
# feed the traces into AI Coding Assistants to fix things.
#WRITE_TRACES_TO_FILES=true

PYTHONUNBUFFERED=1
